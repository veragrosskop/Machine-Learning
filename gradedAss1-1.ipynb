{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Graded Lab Assignment: Logistic Regression\n",
    "\n",
    "In this assignment you will classify hand-written digits using logistic regression.\n",
    "\n",
    "The assignment follows Andrew Ng's explanation of Logistic Regression and (re)watching his videos could be useful (Week 3)\n",
    "\n",
    "Publish your notebook (ipynb file) to your Machine Learning repository on Github ON TIME. We will check the last commit on the day of the deadline. \n",
    "\n",
    "### Deadline Tuesday, October 10th, 23:59\n",
    "\n",
    "Do not hand in any other files, the Notebook should contain all your answers.\n",
    "\n",
    "The points for the assignmnet are distributed as follows:\n",
    "* The implementation\n",
    "    - prediction_function\n",
    "    - cost_function\n",
    "    - compute_gradient\n",
    "    - correct stop condition\n",
    "    - preventing overfitting\n",
    "    - systematically choosing learning rate \n",
    "    - \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is a toolkit that has several datasets built in. You first need to install the toolkit: http://scikit-learn.org/stable/install.html\n",
    "\n",
    "The MNIST dataset that you will be using for this assignment contains images of hand-written digits that are only 8 by 8 pixels, which means the algorithm (logistic regression) should run on every computer.\n",
    "\n",
    "The code in the cell below shows how to work with the digits dataset and  how to visualize it. As you can see the numbers are not very clear in 8x8 pixels images, this means we cannot expect our logistic regression will have a very high classification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers shown are: \n",
      " [[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACoCAYAAADw6BWzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c07e240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits(n_class=10)\n",
    "\n",
    "#Create two rows with numbers\n",
    "firstrow = np.hstack(digits.images[:5,:,:])\n",
    "secondrow = np.hstack(digits.images[5:10,:,:])\n",
    "\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "\n",
    "#Show both rows at the same time\n",
    "plt.imshow(np.vstack((firstrow,secondrow)))\n",
    "\n",
    "print (\"The numbers shown are: \\n\", np.vstack((digits.target[:5], digits.target[5:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The implementation\n",
    "\n",
    "You have to implement the next three functions and fill in the body of the loop in order to create a correct implementation of logistic regression. Don't change the definitions of the functions and input parameters.\n",
    "\n",
    "(1) Make sure that you do not overfit by keeping track of the score on the test set and implementing a correct stop condition. \n",
    "(2) Systematically pick a learning rate alpha that makes sure the algorithm learns in a smooth and stable manner (show how you do it). \n",
    "(3) Plot how your score on the test set improves over time. My best score was about 85% correct!\n",
    "(4) Make sure to comment your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a prediction function h\n",
    "def prediction_function(x,theta):\n",
    "    #as x is printed later it needs to be :\n",
    "    #z = theta.T * x.T\n",
    "    z = dot(theta.T,x) #no need to transpose x because it is done later\n",
    "    x_predict = 1 / (exp(- z))\n",
    "    return x_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use the output of that function to compute the cost function J:\n",
    "def cost_function(x_predict,y):\n",
    "    #minimize the sum of squared errors\n",
    "    #use logistic regression and use the number of rows in x_predict for m\n",
    "    m = x.shape[0]\n",
    "    #J = (1/(2*m))*(X*theta - x_predict)*(X*theta - x_predict).T\n",
    "    J =  -(1/m)*(dot((y),log(x_predict))+dot((1-y),log(1-x_predict)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a function that returns the gradient values, given h (x_predict), y and x:\n",
    "def compute_gradient(x_predict, y, x):\n",
    "    m = x.shape[0]\n",
    "    gradient = (1/m)*dot(x.T, (x_predict - y))\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vera/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:7: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (64,1) and (10,10) not aligned: 1 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d1d64174d1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#x[j,:] should be 1,64 (jth value with 64 features) > transposed in gradient function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;31m#update theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7f91e716bc51>\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(x_predict, y, x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (64,1) and (10,10) not aligned: 1 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "#Choose a suitable learning rate\n",
    "alpha = 0.05\n",
    "iterations = 4 #25 officially\n",
    "theta = np.zeros((64,10))\n",
    "\n",
    "#It is important to check that you're not overfitting by testing your prediction on a testset\n",
    "x = np.reshape(digits.images[:1500],(1500,64))\n",
    "x_test = np.reshape(digits.images[1500:],(297,64))\n",
    "\n",
    "#what does this do exactly?\n",
    "target = digits.target[:1500]\n",
    "target_test = digits.target[1500:]\n",
    "\n",
    "#print (x[0,:])\n",
    "#training iterations\n",
    "m = x.shape[0]\n",
    "for i in range(iterations):\n",
    "    cost = np.zeros(25)\n",
    "    temp_cost = 0\n",
    "    for j in range(m):\n",
    "        #hypothesis\n",
    "        x_predict = prediction_function(x[j,:].T,theta)\n",
    "        print(shape(x_predict)) #test\n",
    "        print(x_predict) #test\n",
    "\n",
    "        #initiate y\n",
    "        #selects which digit it is? or adapts probability in J?\n",
    "        y = np.zeros(10)\n",
    "        y[target[j]] = 1 \n",
    "        \n",
    "        #cost function\n",
    "        temp_cost += cost_function(x_predict,y)\n",
    "        #print (cost_function(x_predict,y))\n",
    "        \n",
    "        #gradient descent step\n",
    "        gradient = compute_gradient(reshape(x_predict,(10,1)), reshape(y,(1,10)), reshape(x[j,:],(1,64))) \n",
    "        #x[j,:] should be 1,64 (jth value with 64 features) > transposed in gradient function\n",
    "        theta = theta - alpha * gradient #update theta\n",
    "    cost[i] = temp_cost\n",
    "print (cost)\n",
    "plt.plot(list(range(iterations)),cost,'bs')\n",
    "\n",
    "#This problem uses multiclass classification.???? This is why we use the above algorithm with the y vector. \n",
    "#To keep track of which number we have identified for a certain position?\n",
    "\n",
    "#plt.plot(x,prediction_function(x.T,theta))\n",
    "#plt.plot(x,y,'o')\n",
    "#plt.show()\n",
    "    \n",
    "# #In Andrew Ng's presentation he says that y needs to be 1 or 0.\n",
    "# #You can use the following example code in the inner loop of your implementation\n",
    "# y = np.zeros(10) #First create a y vector with only zeros\n",
    "# y[target[j]] = 1 #Then set the right class equal to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 64)\n",
      "(10,)\n",
      "(1, 10)\n",
      "[[  0.00000000e+00   2.16669124e-67   2.16669124e-67   2.16669124e-67\n",
      "    2.16669124e-67   2.16669124e-67   2.16669124e-67   2.16669124e-67\n",
      "    2.16669124e-67   2.16669124e-67]]\n",
      "(64, 1)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (x.shape)\n",
    "print (x_predict.shape)\n",
    "print ((x_predict - y.reshape(1,10)).shape)\n",
    "print ((x_predict - y.reshape(1,10)))\n",
    "print (reshape(x[j,:],(1,64)).T.shape) #Why not 64,1 straight away?\n",
    "print (theta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([0,1,2])\n",
    "W += np.array([2,3,4])\n",
    "print (W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]]\n",
      "[1 2 3]\n",
      "(3,)\n",
      "[[1 2 3]]\n",
      "(1, 3)\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [1,2,3]])\n",
    "print(a)\n",
    "print(a[1,:])\n",
    "print((a[1,:]).shape)\n",
    "print(reshape(a[1,:],(1,3)))\n",
    "print((reshape(a[1,:],(1,3))).shape)\n",
    "print(reshape(a[1,:],(3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
